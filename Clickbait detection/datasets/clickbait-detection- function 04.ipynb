{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers pandas scikit-learn seaborn matplotlib requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T08:52:25.735335Z","iopub.execute_input":"2024-04-21T08:52:25.736316Z","iopub.status.idle":"2024-04-21T08:52:38.155449Z","shell.execute_reply.started":"2024-04-21T08:52:25.736281Z","shell.execute_reply":"2024-04-21T08:52:38.154169Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport requests\nimport zipfile\nimport os\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:38.158197Z","iopub.execute_input":"2024-04-21T08:52:38.159110Z","iopub.status.idle":"2024-04-21T08:52:38.166298Z","shell.execute_reply.started":"2024-04-21T08:52:38.159047Z","shell.execute_reply":"2024-04-21T08:52:38.165284Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"!wget https://gist.githubusercontent.com/amitness/0a2ddbcb61c34eab04bad5a17fd8c86b/raw/66ad13dfac4bd1201e09726677dd8ba8048bb8af/clickbait.csv","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:38.167674Z","iopub.execute_input":"2024-04-21T08:52:38.167955Z","iopub.status.idle":"2024-04-21T08:52:39.380313Z","shell.execute_reply.started":"2024-04-21T08:52:38.167931Z","shell.execute_reply":"2024-04-21T08:52:39.378982Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"--2024-04-21 08:52:39--  https://gist.githubusercontent.com/amitness/0a2ddbcb61c34eab04bad5a17fd8c86b/raw/66ad13dfac4bd1201e09726677dd8ba8048bb8af/clickbait.csv\nResolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1835406 (1.8M) [text/plain]\nSaving to: 'clickbait.csv.1'\n\nclickbait.csv.1     100%[===================>]   1.75M  --.-KB/s    in 0.03s   \n\n2024-04-21 08:52:39 (69.6 MB/s) - 'clickbait.csv.1' saved [1835406/1835406]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/clickbait.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.383005Z","iopub.execute_input":"2024-04-21T08:52:39.383377Z","iopub.status.idle":"2024-04-21T08:52:39.433337Z","shell.execute_reply.started":"2024-04-21T08:52:39.383337Z","shell.execute_reply":"2024-04-21T08:52:39.432343Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.434589Z","iopub.execute_input":"2024-04-21T08:52:39.434911Z","iopub.status.idle":"2024-04-21T08:52:39.443935Z","shell.execute_reply.started":"2024-04-21T08:52:39.434877Z","shell.execute_reply":"2024-04-21T08:52:39.443216Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ClickbaitDataset(Dataset):\n    def __init__(self, titles, labels, tokenizer, max_len):\n        self.titles = titles\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.titles)\n\n    def __getitem__(self, item):\n        title = str(self.titles[item])\n        label = self.labels[item]\n\n        encoding = self.tokenizer.encode_plus(\n          title,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          return_token_type_ids=False,\n          pad_to_max_length=True,\n          return_attention_mask=True,\n          return_tensors='pt',\n        )\n\n        return {\n          'title_text': title,\n          'input_ids': encoding['input_ids'].flatten(),\n          'attention_mask': encoding['attention_mask'].flatten(),\n          'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.444972Z","iopub.execute_input":"2024-04-21T08:52:39.445274Z","iopub.status.idle":"2024-04-21T08:52:39.455198Z","shell.execute_reply.started":"2024-04-21T08:52:39.445250Z","shell.execute_reply":"2024-04-21T08:52:39.454104Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.456497Z","iopub.execute_input":"2024-04-21T08:52:39.456845Z","iopub.status.idle":"2024-04-21T08:52:39.677071Z","shell.execute_reply.started":"2024-04-21T08:52:39.456814Z","shell.execute_reply":"2024-04-21T08:52:39.676176Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"max_len = 128\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.678497Z","iopub.execute_input":"2024-04-21T08:52:39.678801Z","iopub.status.idle":"2024-04-21T08:52:39.683013Z","shell.execute_reply.started":"2024-04-21T08:52:39.678776Z","shell.execute_reply":"2024-04-21T08:52:39.681914Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n    ds = ClickbaitDataset(\n        titles=df.title.to_numpy(),\n        labels=df.label.to_numpy(),\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n\n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        num_workers=2\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.684407Z","iopub.execute_input":"2024-04-21T08:52:39.684760Z","iopub.status.idle":"2024-04-21T08:52:39.693293Z","shell.execute_reply.started":"2024-04-21T08:52:39.684728Z","shell.execute_reply":"2024-04-21T08:52:39.692322Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_data_loader = create_data_loader(train_df, tokenizer, max_len, batch_size)\nval_data_loader = create_data_loader(val_df, tokenizer, max_len, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.698184Z","iopub.execute_input":"2024-04-21T08:52:39.698532Z","iopub.status.idle":"2024-04-21T08:52:39.705691Z","shell.execute_reply.started":"2024-04-21T08:52:39.698508Z","shell.execute_reply":"2024-04-21T08:52:39.704871Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\nmodel = model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:39.707481Z","iopub.execute_input":"2024-04-21T08:52:39.707737Z","iopub.status.idle":"2024-04-21T08:52:40.282009Z","shell.execute_reply.started":"2024-04-21T08:52:39.707714Z","shell.execute_reply":"2024-04-21T08:52:40.281221Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:40.283327Z","iopub.execute_input":"2024-04-21T08:52:40.283627Z","iopub.status.idle":"2024-04-21T08:52:40.293618Z","shell.execute_reply.started":"2024-04-21T08:52:40.283603Z","shell.execute_reply":"2024-04-21T08:52:40.292731Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:40.295212Z","iopub.execute_input":"2024-04-21T08:52:40.295493Z","iopub.status.idle":"2024-04-21T08:52:52.634534Z","shell.execute_reply.started":"2024-04-21T08:52:40.295469Z","shell.execute_reply":"2024-04-21T08:52:52.633559Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_epoch(model, data_loader, optimizer, device, n_examples):\n    model = model.train()\n\n    losses = []\n    correct_predictions = 0\n\n    # Set up the progress bar\n    progress_bar = tqdm(data_loader, desc='Training', leave=False)\n\n    for d in progress_bar:\n        input_ids = d[\"input_ids\"].to(device)\n        attention_mask = d[\"attention_mask\"].to(device)\n        labels = d[\"labels\"].to(device)\n\n        outputs = model(\n          input_ids=input_ids,\n          attention_mask=attention_mask,\n          labels=labels\n        )\n\n        loss = outputs[0]\n        logits = outputs[1]\n        _, preds = torch.max(logits, dim=1)\n        correct_predictions += torch.sum(preds == labels)\n        losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        running_loss = np.mean(losses)\n        running_accuracy = correct_predictions.double() / n_examples\n        \n        progress_bar.set_postfix({\n            'loss': f'{running_loss:.4f}',\n            'acc': f'{running_accuracy:.4f}'\n        })\n    \n    progress_bar.close()\n    return correct_predictions.double() / n_examples, np.mean(losses)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:52:52.636059Z","iopub.execute_input":"2024-04-21T08:52:52.636396Z","iopub.status.idle":"2024-04-21T08:52:52.646685Z","shell.execute_reply.started":"2024-04-21T08:52:52.636366Z","shell.execute_reply":"2024-04-21T08:52:52.645678Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    train_acc, train_loss = train_epoch(\n        model,\n        train_data_loader,\n        optimizer,\n        device='cuda',\n        n_examples=len(train_df)\n    )\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:34.725656Z","iopub.execute_input":"2024-04-21T08:54:34.726267Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1600 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n                                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train loss 0.033697033705902865 accuracy 0.9880412693450055\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1600 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n                                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train loss 0.009607010565378004 accuracy 0.9969516961075504\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1600 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n                                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train loss 0.005557714428850886 accuracy 0.998632171330311\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1600 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n                                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train loss 0.0045272355472502565 accuracy 0.9988666562451148\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1600 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTraining:   2%|â–         | 39/1600 [00:07<05:05,  5.10it/s, loss=0.0008, acc=0.0244]","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'clickbait_classifier_model.bin')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.282707Z","iopub.status.idle":"2024-04-21T08:54:04.283069Z","shell.execute_reply.started":"2024-04-21T08:54:04.282879Z","shell.execute_reply":"2024-04-21T08:54:04.282894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, device, n_examples):\n    model = model.eval()\n\n    predictions = []\n    real_values = []\n\n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d['input_ids'].to(device)\n            attention_mask = d['attention_mask'].to(device)\n            labels = d['labels'].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n\n            _, preds = torch.max(outputs[0], dim=1)\n\n            predictions.extend(preds)\n            real_values.extend(labels)\n\n    predictions = torch.stack(predictions).cpu()\n    real_values = torch.stack(real_values).cpu()\n    return predictions, real_values","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.284134Z","iopub.status.idle":"2024-04-21T08:54:04.284521Z","shell.execute_reply.started":"2024-04-21T08:54:04.284331Z","shell.execute_reply":"2024-04-21T08:54:04.284347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, real_values = eval_model(\n    model,\n    val_data_loader,\n    device='cuda',\n    n_examples=len(val_df)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.285830Z","iopub.status.idle":"2024-04-21T08:54:04.286213Z","shell.execute_reply.started":"2024-04-21T08:54:04.286006Z","shell.execute_reply":"2024-04-21T08:54:04.286021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(real_values, predictions, target_names=['Non-Clickbait', 'Clickbait']))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.287614Z","iopub.status.idle":"2024-04-21T08:54:04.287941Z","shell.execute_reply.started":"2024-04-21T08:54:04.287781Z","shell.execute_reply":"2024-04-21T08:54:04.287794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(real_values, predictions)\ndf_cm = pd.DataFrame(cm, index=['Non-Clickbait', 'Clickbait'], columns=['Non-Clickbait', 'Clickbait'])\n\n# Plotting the heatmap\nplt.figure(figsize=(10, 7))\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.290181Z","iopub.status.idle":"2024-04-21T08:54:04.290504Z","shell.execute_reply.started":"2024-04-21T08:54:04.290343Z","shell.execute_reply":"2024-04-21T08:54:04.290356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_url = 'https://zenodo.org/records/6362726/files/webis-clickbait-22.zip'\nzip_path = 'data.zip'\n\nresponse = requests.get(zip_url)\nwith open(zip_path, 'wb') as f:\n    f.write(response.content)\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall('data')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.291568Z","iopub.status.idle":"2024-04-21T08:54:04.291908Z","shell.execute_reply.started":"2024-04-21T08:54:04.291741Z","shell.execute_reply":"2024-04-21T08:54:04.291755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = 'data'\noutput_file = 'target_descriptions.txt'\n\nwith open(output_file, 'w', encoding='utf-8') as out_f:\n    # List all files in the data directory\n    for filename in os.listdir(data_dir):\n        # Check if the file is a .jsonl file\n        if filename.endswith('.jsonl'):\n            # Open the .jsonl file\n            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n                # Read each line in the .jsonl file\n                for line in file:\n                    try:\n                        # Parse JSON object from line\n                        json_obj = json.loads(line)\n                        # Write the 'targetDescription' field to the output file\n                        target_description = json_obj.get('targetDescription', '')\n                        if target_description and len(target_description) >= 10:\n                            out_f.write(target_description + '\\n')\n                    except json.JSONDecodeError:\n                        continue\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.292930Z","iopub.status.idle":"2024-04-21T08:54:04.293292Z","shell.execute_reply.started":"2024-04-21T08:54:04.293122Z","shell.execute_reply":"2024-04-21T08:54:04.293137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/working/target_descriptions.txt'\n\nunlabeled_titles = []\n\nwith open(file_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        title = line.strip()\n        if title:\n            unlabeled_titles.append(title)\n\nprint(f\"Loaded {len(unlabeled_titles)} titles from the file.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.294402Z","iopub.status.idle":"2024-04-21T08:54:04.294751Z","shell.execute_reply.started":"2024-04-21T08:54:04.294571Z","shell.execute_reply":"2024-04-21T08:54:04.294586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnlabeledDataset(Dataset):\n    def __init__(self, titles, tokenizer, max_len):\n        self.titles = titles\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.titles)\n\n    def __getitem__(self, item):\n        title = str(self.titles[item])\n\n        encoding = self.tokenizer.encode_plus(\n            title,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten()\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.295726Z","iopub.status.idle":"2024-04-21T08:54:04.296098Z","shell.execute_reply.started":"2024-04-21T08:54:04.295895Z","shell.execute_reply":"2024-04-21T08:54:04.295909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unlabeled_dataset = UnlabeledDataset(unlabeled_titles, tokenizer, max_len)\nunlabeled_loader = DataLoader(unlabeled_dataset, batch_size=16, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.297639Z","iopub.status.idle":"2024-04-21T08:54:04.297998Z","shell.execute_reply.started":"2024-04-21T08:54:04.297814Z","shell.execute_reply":"2024-04-21T08:54:04.297829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\nteacher_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\nmodel_path = '/kaggle/working/clickbait_classifier_model.bin'\nteacher_model.load_state_dict(torch.load(model_path))\n\nteacher_model = teacher_model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.299578Z","iopub.status.idle":"2024-04-21T08:54:04.299897Z","shell.execute_reply.started":"2024-04-21T08:54:04.299739Z","shell.execute_reply":"2024-04-21T08:54:04.299753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pseudo_labels(model, data_loader, device):\n    model.eval()\n    predictions = []\n\n    with torch.no_grad():\n        for d in tqdm(data_loader, desc='Generating pseudo-labels'):\n            input_ids = d['input_ids'].to(device)\n            attention_mask = d['attention_mask'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs.logits, dim=1)\n            predictions.extend(preds.cpu().numpy())\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.301138Z","iopub.status.idle":"2024-04-21T08:54:04.301481Z","shell.execute_reply.started":"2024-04-21T08:54:04.301312Z","shell.execute_reply":"2024-04-21T08:54:04.301326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pseudo_labels = get_pseudo_labels(teacher_model, unlabeled_loader, 'cuda')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.302789Z","iopub.status.idle":"2024-04-21T08:54:04.303149Z","shell.execute_reply.started":"2024-04-21T08:54:04.302955Z","shell.execute_reply":"2024-04-21T08:54:04.302969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_titles = list(train_df['title']) + unlabeled_titles\ncombined_labels = list(train_df['label']) + pseudo_labels\n\ncombined_dataset = ClickbaitDataset(combined_titles, combined_labels, tokenizer, max_len)\ncombined_loader = DataLoader(combined_dataset, batch_size=16, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.304771Z","iopub.status.idle":"2024-04-21T08:54:04.305175Z","shell.execute_reply.started":"2024-04-21T08:54:04.304967Z","shell.execute_reply":"2024-04-21T08:54:04.304981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"student_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, problem_type=\"single_label_classification\", hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\nstudent_model.to('cuda')\n\noptimizer = AdamW(student_model.parameters(), lr=2e-5)\n\nfor epoch in range(3):\n    print(f'Epoch {epoch + 1}/3')\n    train_acc, train_loss = train_epoch(\n        student_model,\n        combined_loader,\n        optimizer,\n        'cuda',\n        len(combined_dataset)\n    )\n    print(f'Train loss {train_loss} accuracy {train_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.306405Z","iopub.status.idle":"2024-04-21T08:54:04.306723Z","shell.execute_reply.started":"2024-04-21T08:54:04.306564Z","shell.execute_reply":"2024-04-21T08:54:04.306578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_predictions, s_real_values = eval_model(\n    student_model,\n    val_data_loader,\n    device='cuda',\n    n_examples=len(val_df)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.308080Z","iopub.status.idle":"2024-04-21T08:54:04.308441Z","shell.execute_reply.started":"2024-04-21T08:54:04.308269Z","shell.execute_reply":"2024-04-21T08:54:04.308283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(s_real_values, s_predictions, target_names=['Non-Clickbait', 'Clickbait']))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.310642Z","iopub.status.idle":"2024-04-21T08:54:04.311117Z","shell.execute_reply.started":"2024-04-21T08:54:04.310861Z","shell.execute_reply":"2024-04-21T08:54:04.310880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(s_real_values, s_predictions)\ndf_cm = pd.DataFrame(cm, index=['Non-Clickbait', 'Clickbait'], columns=['Non-Clickbait', 'Clickbait'])\n\n# Plotting the heatmap\nplt.figure(figsize=(10, 7))\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:54:04.313140Z","iopub.status.idle":"2024-04-21T08:54:04.313605Z","shell.execute_reply.started":"2024-04-21T08:54:04.313360Z","shell.execute_reply":"2024-04-21T08:54:04.313379Z"},"trusted":true},"execution_count":null,"outputs":[]}]}